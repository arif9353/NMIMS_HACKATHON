{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required libraries \n",
    "import speech_recognition as sr\n",
    "from translate import Translator\n",
    "import io, base64\n",
    "from pydub import AudioSegment\n",
    "from ttsmms import TTS \n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASES OF INPUT FOR THE USER TO QUERY THE PDF:\n",
    "1. HINDI SPEECH WILL BE USED\n",
    "2. ENGLISH SPEECH WILL BE USED\n",
    "3. HINDI TEXT WILL BE USED \n",
    "4. ENGLISH TEXT WILL BE USED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. INPUT IN THE FORM OF HINDI SPEECH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the hindi audio file first and encoding it into base64 format, because audio file will be recieved in encoded base64 format from the react frontend\n",
    "hindi_audio_path = \".\\hindi_audio.mp3\"\n",
    "def encode_mp3_to_base64(file_path):\n",
    "    with open(file_path, 'rb') as mp3_file:\n",
    "        mp3_binary_data = mp3_file.read()\n",
    "        base64_encoded = base64.b64encode(mp3_binary_data)\n",
    "        return base64_encoded.decode('utf-8')\n",
    "\n",
    "encoded_audio_hindi = encode_mp3_to_base64(hindi_audio_path)\n",
    "encoded_audio_hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now decoding the audio file which was encoded above. THIS FUNCTIONALITY IS THE STARTING POINT IN THE BACKEND.\n",
    "decoded_audio_hindi = base64.b64decode(encoded_audio_hindi)\n",
    "decoded_audio_hindi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting this decoded base64 into wav format.\n",
    "audio_hindi = AudioSegment.from_mp3(io.BytesIO(decoded_audio_hindi))\n",
    "wav_data_hindi = io.BytesIO()\n",
    "audio_hindi.export(wav_data_hindi, format=\"wav\")\n",
    "wav_data_hindi.seek(0)\n",
    "wav_converted_hindi = wav_data_hindi.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing hindi speech to text conversion using python's speech_recognition library \n",
    "def wav_to_hindi_text(audio_content):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_stream = io.BytesIO(audio_content)\n",
    "    with sr.AudioFile(audio_stream) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    text = recognizer.recognize_google(audio, language = 'hi-IN')\n",
    "    return text\n",
    "\n",
    "hindi_query_text = wav_to_hindi_text(wav_converted_hindi)\n",
    "hindi_query_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing hindi text to english translation as this text will be used for querying the pdf\n",
    "#For this we will use python's translate library\n",
    "def hindi_to_english_text(hindi_text):\n",
    "    translator = Translator(to_lang=\"en\", from_lang=\"hi\")\n",
    "    translated_text = translator.translate(hindi_text)\n",
    "    return translated_text\n",
    "\n",
    "english_query_text = hindi_to_english_text(hindi_query_text)\n",
    "english_query_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as in the flow, This english_query_text will be provided as a prompt for our LLM which will be trained on a pdf, the result provided by this LLM will now undergo conversions stated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the LLM is not ready, let us assume the response from the LLM to be english_result_text\n",
    "english_result_text = '''\n",
    "An atom is the basic building block of matter, consisting of a nucleus composed of protons and neutrons, surrounded by electrons in orbit. The nucleus is at the center of the atom and contains positively charged protons and uncharged neutrons. Electrons, which are negatively charged, orbit the nucleus in shells or energy levels.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will translate this english_result_text in hindi, again using the translate library of python\n",
    "def english_to_hindi_text(english_text):\n",
    "    translator = Translator(to_lang=\"hi\", from_lang='en')\n",
    "    translated_text = translator.translate(english_text)\n",
    "    return translated_text\n",
    "\n",
    "hindi_result_text = english_to_hindi_text(english_result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing text-to-speech using python's ttsmms and a model which is stored in models folder.\n",
    "def hindi_text_to_audio(text):\n",
    "    dir_path = (\"./models/hin\")\n",
    "    tts=TTS(dir_path)\n",
    "    synthesized_wav=tts.synthesis(text)\n",
    "    return synthesized_wav\n",
    "\n",
    "hindi_result_audio = hindi_text_to_audio(hindi_result_text)\n",
    "#displaying the audio:\n",
    "ipd.Audio(hindi_result_audio[\"x\"], rate=hindi_result_audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the audio file to base64 format, this will be sent as an output to the frontend along the the hindi_result_text\n",
    "def encoding_hindi_audio(synthesized_wav):\n",
    "    wav=synthesized_wav[\"x\"]\n",
    "    wav_binary = wav.tobytes()\n",
    "    base64_encoded = base64.b64encode(wav_binary).decode('utf-8')\n",
    "    return base64_encoded\n",
    "base64encodedaudio = encoding_hindi_audio(hindi_result_audio)\n",
    "base64encodedaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. INPUT IN THE FORM OF ENGLISH SPEECH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the hindi audio file first and encoding it into base64 format, because audio file will be recieved in encoded base64 format from the react frontend\n",
    "english_audio_path = \".\\english_audio.mp3\"\n",
    "encoded_audio_english = encode_mp3_to_base64(english_audio_path)\n",
    "encoded_audio_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now decoding the audio file which was encoded above. THIS FUNCTIONALITY IS THE STARTING POINT IN THE BACKEND.\n",
    "decoded_audio_english = base64.b64decode(encoded_audio_english)\n",
    "decoded_audio_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting this decoded base64 into wav format.\n",
    "audio_english = AudioSegment.from_mp3(io.BytesIO(decoded_audio_english))\n",
    "wav_data_english = io.BytesIO()\n",
    "audio_english.export(wav_data_english, format=\"wav\")\n",
    "wav_data_english.seek(0)\n",
    "wav_converted_english = wav_data_english.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing english speech to text conversion using python's speech_recognition library \n",
    "def wav_to_english_text(audio_content):\n",
    "    recognizer = sr.Recognizer()\n",
    "    audio_stream = io.BytesIO(audio_content)\n",
    "    with sr.AudioFile(audio_stream) as source:\n",
    "        audio = recognizer.record(source)\n",
    "    text = recognizer.recognize_google(audio, language = 'en-US')\n",
    "    return text\n",
    "\n",
    "english_query_text = wav_to_english_text(wav_converted_english)\n",
    "english_query_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as in the flow, This english_query_text will be provided as a prompt for our LLM which will be trained on a pdf, the result provided by this LLM will now undergo conversions stated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the LLM is not ready, let us assume the response from the LLM to be english_result_text\n",
    "english_result_text = '''\n",
    "An atom is the basic building block of matter, consisting of a nucleus composed of protons and neutrons, surrounded by electrons in orbit. The nucleus is at the center of the atom and contains positively charged protons and uncharged neutrons. Electrons, which are negatively charged, orbit the nucleus in shells or energy levels.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing text-to-speech using python's ttsmms and a model which is stored in models folder.\n",
    "def english_text_to_audio(text):\n",
    "    dir_path = (\"./models/eng\")\n",
    "    tts=TTS(dir_path)\n",
    "    synthesized_wav=tts.synthesis(text)\n",
    "    return synthesized_wav\n",
    "\n",
    "english_result_audio = english_text_to_audio(english_result_text)\n",
    "#displaying the audio:\n",
    "ipd.Audio(english_result_audio[\"x\"], rate=english_result_audio[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. INPUT IN THE FORM OF HINDI TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's assume the input text entered by the user is hindi_query_text:\n",
    "hindi_query_text = \"नमस्ते, मैं आरिफ हूं और मैं वर्तमान में एक प्रोजेक्ट पर काम कर रहा हूं जो लैंगचेन, क्रोमाडीबी और हगिंगफेस का उपयोग करता है\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_query_text = hindi_to_english_text(hindi_query_text)\n",
    "english_query_text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as in the flow, This english_text will be provided as a prompt for our LLM which will be trained on a pdf, the result provided by this LLM will now undergo conversions stated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As the LLM is not ready, let us assume the response from the LLM to be english_result_text, this result will then be given to the user as the final result displayed.\n",
    "english_result_text = '''\n",
    "An atom is the basic building block of matter, consisting of a nucleus composed of protons and neutrons, surrounded by electrons in orbit. The nucleus is at the center of the atom and contains positively charged protons and uncharged neutrons. Electrons, which are negatively charged, orbit the nucleus in shells or energy levels.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. INPUT IN THE FORM OF ENGLISH TEXT <br>\n",
    "In this case, there is no need for any conversion. The query entered by the user will simply be sent to the LLM and the answer will be returned to the user."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
